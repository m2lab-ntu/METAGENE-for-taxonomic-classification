# METAGENE Classification User Guide
# ä½¿ç”¨è€…å®Œæ•´æŒ‡å—

æœ¬æŒ‡å—åŒ…å«æ‰€æœ‰ä½¿ç”¨è€…éœ€è¦çš„è³‡è¨Šï¼šå¿«é€Ÿé–‹å§‹ã€è¨“ç·´è‡ªå·±çš„è³‡æ–™é›†ã€ç†è§£è¼¸å‡ºæª”æ¡ˆã€‚

---

## ğŸ“– ç›®éŒ„

1. [å¿«é€Ÿé–‹å§‹ - RTX 4090](#å¿«é€Ÿé–‹å§‹---rtx-4090)
2. [è¨“ç·´æ‚¨çš„è³‡æ–™é›†](#è¨“ç·´æ‚¨çš„è³‡æ–™é›†)
3. [è¼¸å‡ºæª”æ¡ˆè©³è§£](#è¼¸å‡ºæª”æ¡ˆè©³è§£)
4. [å¸¸è¦‹å•é¡Œèˆ‡æ•…éšœæ’é™¤](#å¸¸è¦‹å•é¡Œèˆ‡æ•…éšœæ’é™¤)

---

# å¿«é€Ÿé–‹å§‹ - RTX 4090

## âœ… å·²é©—è­‰å¯è¡Œï¼

RTX 4090 (24GB) å¯ä»¥æˆåŠŸè¨“ç·´ METAGENE-1 (7B) - **å³°å€¼è¨˜æ†¶é«”ä½¿ç”¨ï¼š13GB**

---

## ğŸš€ ä¸‰æ­¥é©Ÿé–‹å§‹è¨“ç·´

### æ­¥é©Ÿ 1ï¼šè¨­ç½®ç’°å¢ƒ

```bash
cd /media/user/disk2/METAGENE/classification
source setup_env.sh
```

### æ­¥é©Ÿ 2ï¼šæ¸¬è©¦ï¼ˆå¯é¸ï¼‰

```bash
# ç”¨ç¯„ä¾‹è³‡æ–™æ¸¬è©¦ (~3åˆ†é˜)
bash test_optimized_training.sh
```

### æ­¥é©Ÿ 3ï¼šè¨“ç·´ä½ çš„è³‡æ–™

```bash
python train.py \
  --config configs/rtx4090_optimized.yaml \
  --train_fasta YOUR_TRAIN.fa \
  --val_fasta YOUR_VAL.fa \
  --mapping_tsv YOUR_MAPPING.tsv \
  --output_dir outputs/my_experiment \
  --max_epochs 10
```

---

## ğŸ“ å®Œæ•´ç¯„ä¾‹

```bash
# è¨­ç½®ç’°å¢ƒ
export HF_HOME=/media/user/disk2/.cache/huggingface
export TRANSFORMERS_CACHE=/media/user/disk2/.cache/huggingface
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True,max_split_size_mb:128

# æ¿€æ´»ç’°å¢ƒ
conda activate METAGENE

# æ¸…ç©º GPU è¨˜æ†¶é«”
python -c "import torch; torch.cuda.empty_cache()"

# é–‹å§‹è¨“ç·´
python train.py \
  --config configs/rtx4090_optimized.yaml \
  --train_fasta data/train.fa \
  --val_fasta data/val.fa \
  --mapping_tsv data/mapping.tsv \
  --output_dir outputs/species_classification \
  --batch_size 1 \
  --max_epochs 10 \
  2>&1 | tee training.log
```

---

## ğŸ›ï¸ RTX 4090 é—œéµå„ªåŒ–è¨­ç½®

| åƒæ•¸ | å€¼ | ç¯€çœè¨˜æ†¶é«” |
|------|-----|----------|
| `max_length` | 128 | 60% |
| `batch_size` | 1 | æœ€å°ä½”ç”¨ |
| `grad_accum_steps` | 8 | ä¿æŒæœ‰æ•ˆ batch=8 |
| `lora.r` | 4 | æ¸›å°‘åƒæ•¸ |
| `lora.target_modules` | [q_proj, v_proj] | åªè¨“ç·´é—œéµæ¨¡çµ„ |
| `gradient_checkpointing` | true | **50% activation memory** |

**çµæœ**: è¨˜æ†¶é«”ä½¿ç”¨ 13GB / 24GB âœ“

---

## ğŸ“Š é æœŸçµæœ

### è¨˜æ†¶é«”ä½¿ç”¨
- **å³°å€¼**: 13GB / 24GB âœ“
- **å¹³å‡**: ~13GB
- **å®‰å…¨é‚Šç•Œ**: 11GB å‰©é¤˜

### è¨“ç·´é€Ÿåº¦
- **å°è³‡æ–™é›†** (1K reads): ~30 åˆ†é˜/10 epochs
- **ä¸­è³‡æ–™é›†** (10K reads): ~5 å°æ™‚/10 epochs
- **å¤§è³‡æ–™é›†** (100K reads): ~50 å°æ™‚/10 epochs

### è¼¸å‡ºæª”æ¡ˆ
```
outputs/YOUR_EXPERIMENT/
â”œâ”€â”€ checkpoints/best.pt          # æœ€ä½³æ¨¡å‹
â”œâ”€â”€ final_model/                 # ç”¨æ–¼æ¨ç†
â”œâ”€â”€ plots/training_curves.png    # è¨“ç·´æ›²ç·š
â””â”€â”€ final_metrics.json           # æœ€çµ‚æŒ‡æ¨™
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### å•é¡Œ 1ï¼šé‚„æ˜¯ OOMï¼Ÿ

**è§£æ±ºæ–¹æ¡ˆ A**: æ¸›å°‘åºåˆ—é•·åº¦
```bash
python train.py --config configs/rtx4090_optimized.yaml --max_length 64 ...
```

**è§£æ±ºæ–¹æ¡ˆ B**: Ultra-safe æ¨¡å¼
```yaml
tokenizer:
  max_length: 64
model:
  lora:
    r: 2
    target_modules: [q_proj]
```

### å•é¡Œ 2ï¼šè¨“ç·´å¤ªæ…¢ï¼Ÿ

**è§£æ±ºæ–¹æ¡ˆ**: ç¨å¤§çš„ batch size
```yaml
training:
  batch_size: 2
  grad_accum_steps: 4
tokenizer:
  max_length: 96
```

### å•é¡Œ 3ï¼šæº–ç¢ºåº¦ä¸å¤ ï¼Ÿ

**è§£æ±ºæ–¹æ¡ˆ A**: å¢åŠ è¨“ç·´æ™‚é–“
```bash
python train.py --config configs/rtx4090_optimized.yaml --max_epochs 20 ...
```

**è§£æ±ºæ–¹æ¡ˆ B**: æ›´å¤§çš„ LoRA rank
```yaml
model:
  lora:
    r: 8
    target_modules: [q_proj, k_proj, v_proj, o_proj]
```
**æ³¨æ„**: é€™æœƒå¢åŠ è¨˜æ†¶é«”ä½¿ç”¨åˆ° ~16-18GB

---

## ğŸ“ˆ ç›£æ§è¨“ç·´

```bash
# æª¢æŸ¥ GPU ä½¿ç”¨
watch -n 1 nvidia-smi

# æŸ¥çœ‹è¨“ç·´ log
tail -f training.log

# å³æ™‚æŸ¥çœ‹æŒ‡æ¨™
cat outputs/YOUR_EXPERIMENT/final_metrics.json
```

---

# è¨“ç·´æ‚¨çš„è³‡æ–™é›†

## è³‡æ–™æ ¼å¼è¦æ±‚

### FASTA Header æ ¼å¼
```
>lbl|{class_id}|{tax_id}|{readlen}|{species_name}/{mate}
```

ç¯„ä¾‹ï¼š
```
>lbl|85|301|45|Pseudomonas-61537/2
CTTCACGGCTGCTCTGGAAACTTTCGGCCTGGGCGGCCAGTTGCGCTTTGAGGTTGGCGTTGAGCTC...
```

### Mapping æª”æ¡ˆæ ¼å¼ (TSV)
```tsv
class_id    label_name                      tax_id
0           Azorhizobium caulinodans        7
1           Buchnera aphidicola             9
2           Dictyoglomus thermophilum       14
```

---

## è¨“ç·´æµç¨‹

### 1. æº–å‚™ Mapping æª”æ¡ˆ

```bash
# è‡ªå‹•è¼‰å…¥ç‰©ç¨®åç¨±
python prepare_species_mapping.py \
  --input_path your_mapping.tab \
  --output_path species_mapping_converted.tsv \
  --species_name_csv species_database.csv

# æˆ–ä¸éœ€è¦ç‰©ç¨®åç¨±ï¼ˆä½¿ç”¨ TaxID_* ä½œç‚ºæ¨™ç±¤ï¼‰
python prepare_species_mapping.py --no_label_name
```

### 2. å¿«é€Ÿæ¸¬è©¦ï¼ˆå»ºè­°å…ˆåŸ·è¡Œï¼‰

åŸ·è¡Œ 1 å€‹ epoch ä¾†é©—è­‰è³‡æ–™æ ¼å¼ï¼š

```bash
python train.py \
  --config configs/rtx4090_optimized.yaml \
  --train_fasta data/train.fa \
  --val_fasta data/val.fa \
  --mapping_tsv species_mapping_converted.tsv \
  --output_dir outputs/quick_test \
  --max_epochs 1
```

### 3. å®Œæ•´è¨“ç·´

```bash
python train.py \
  --config configs/rtx4090_optimized.yaml \
  --train_fasta data/train.fa \
  --val_fasta data/val.fa \
  --mapping_tsv species_mapping_converted.tsv \
  --output_dir outputs/full_training \
  --max_epochs 10
```

---

## è¨“ç·´é…ç½®èªªæ˜

| åƒæ•¸ | é è¨­å€¼ | èªªæ˜ |
|------|-------|------|
| `batch_size` | 1 | æœ€å° batch size |
| `grad_accum_steps` | 8 | æœ‰æ•ˆ batch size = 8 |
| `max_length` | 128 | åºåˆ—é•·åº¦ |
| `gradient_checkpointing` | true | ç¯€çœè¨˜æ†¶é«” |
| `lora.r` | 4 | LoRA rank |
| `lora.target_modules` | [q_proj, v_proj] | è¨“ç·´çš„å±¤ |
| `precision` | bf16-mixed | æ··åˆç²¾åº¦ |

---

## èª¿æ•´è¨“ç·´åƒæ•¸

### æ–¹æ³• 1ï¼šä¿®æ”¹ config æª”æ¡ˆ

ç·¨è¼¯ `configs/rtx4090_optimized.yaml`ï¼š

```yaml
training:
  max_epochs: 20
  batch_size: 2
  
tokenizer:
  max_length: 256
```

### æ–¹æ³• 2ï¼šå‘½ä»¤åˆ—åƒæ•¸

```bash
python train.py \
  --config configs/rtx4090_optimized.yaml \
  --train_fasta data/train.fa \
  --val_fasta data/val.fa \
  --mapping_tsv data/mapping.tsv \
  --output_dir outputs/custom_experiment \
  --batch_size 2 \
  --max_epochs 5
```

---

## è©•ä¼°æ¨¡å‹

```bash
python evaluate.py \
  --ckpt outputs/my_experiment/checkpoints/best.pt \
  --split val \
  --output_dir outputs/evaluation_results
```

---

## ä½¿ç”¨æ¨¡å‹é€²è¡Œé æ¸¬

```bash
python predict.py \
  --ckpt outputs/my_experiment/checkpoints/best.pt \
  --input new_sequences.fa \
  --output predictions.csv
```

---

# è¼¸å‡ºæª”æ¡ˆè©³è§£

## ğŸ—‚ï¸ è¨“ç·´è¼¸å‡ºæª”æ¡ˆ (outputs/my_experiment/)

### æœ€é—œéµçš„ 5 å€‹æª”æ¡ˆ â­

1. **`checkpoints/best.pt`** (13GB)
   - è¨“ç·´å¥½çš„æœ€ä½³æ¨¡å‹
   - ç”¨æ–¼é æ¸¬å’Œè©•ä¼°
   - **æœ€é‡è¦çš„æª”æ¡ˆï¼Œå‹™å¿…å‚™ä»½ï¼**

2. **`final_model/id2label.json`** (~50KB)
   - IDâ†’ç‰©ç¨®åç¨±æ˜ å°„
   - å°‡é æ¸¬çš„æ•¸å­—è½‰æ›ç‚ºç‰©ç¨®åç¨±
   ```json
   {
     "0": "Escherichia coli",
     "1": "Staphylococcus aureus"
   }
   ```

3. **`config.json`** (~2KB)
   - å®Œæ•´è¨“ç·´é…ç½®
   - å¯é‡ç¾è¨“ç·´çµæœçš„é—œéµ

4. **`plots/training_curves.png`** (~1MB)
   - è¨“ç·´/é©—è­‰ loss å’ŒæŒ‡æ¨™æ›²ç·š
   - åˆ¤æ–·è¨“ç·´æ˜¯å¦éæ“¬åˆ

5. **`final_metrics.json`** (~5KB)
   - æœ€çµ‚é©—è­‰æŒ‡æ¨™
   ```json
   {
     "accuracy": 0.8234,
     "macro_f1": 0.8122
   }
   ```

---

### å®Œæ•´æª”æ¡ˆåˆ—è¡¨

| æª”æ¡ˆ | å¤§å° | é‡è¦æ€§ | ç”¨é€” |
|------|------|--------|------|
| `config.json` | ~2KB | â­â­â­â­â­ | å®Œæ•´è¨“ç·´é…ç½® |
| `training.log` | ~249MB | â­â­â­â­ | è¨“ç·´æ—¥èªŒ |
| `checkpoints/best.pt` | ~13GB | â­â­â­â­â­ | æœ€ä½³æ¨¡å‹æ¬Šé‡ |
| `checkpoints/last.pt` | ~13GB | â­â­â­ | æœ€å¾Œ checkpoint |
| `final_model/label2id.json` | ~50KB | â­â­â­â­â­ | ç‰©ç¨®åâ†’ID |
| `final_model/id2label.json` | ~50KB | â­â­â­â­â­ | IDâ†’ç‰©ç¨®å |
| `final_model/seen_classes.txt` | ~10KB | â­â­â­ | è¨“ç·´éçš„é¡åˆ¥ |
| `plots/training_curves.png` | ~1MB | â­â­â­â­ | è¨“ç·´æ›²ç·šåœ– |
| `plots/confusion_matrix.png` | ~2MB | â­â­â­â­ | æ··æ·†çŸ©é™£ |
| `final_metrics.json` | ~5KB | â­â­â­â­ | æœ€çµ‚æŒ‡æ¨™ |
| `train_class_distribution.csv` | ~100KB | â­â­â­ | è¨“ç·´é›†é¡åˆ¥åˆ†å¸ƒ |
| `val_class_distribution.csv` | ~25KB | â­â­â­ | é©—è­‰é›†é¡åˆ¥åˆ†å¸ƒ |

---

## ğŸ§ª æ¸¬è©¦è¼¸å‡ºæª”æ¡ˆ (outputs/my_test/)

| æª”æ¡ˆ | é‡è¦æ€§ | ç”¨é€” |
|------|--------|------|
| `test_metrics.json` | â­â­â­â­â­ | æ•´é«”æ¸¬è©¦æ€§èƒ½ |
| `test_predictions.csv` | â­â­â­â­â­ | æ¯å€‹æ¨£æœ¬çš„é æ¸¬çµæœ |
| `test_classification_report.json` | â­â­â­â­ | æ¯é¡åˆ¥ Precision/Recall/F1 |
| `test_per_class_metrics.csv` | â­â­â­â­ | CSV æ ¼å¼ï¼ˆæ˜“åˆ†æï¼‰ |
| `test_confusion_matrix.png` | â­â­â­â­ | æ··æ·†çŸ©é™£åœ– |

---

### test_predictions.csv æ ¼å¼

```csv
sequence_id,true_label,predicted_label,true_class_id,predicted_class_id,confidence,correct
seq_001,Escherichia coli,Escherichia coli,0,0,0.9823,True
seq_002,Staphylococcus aureus,Enterococcus faecalis,1,5,0.6234,False
```

**é‡è¦æ¬„ä½**ï¼š
- `confidence < 0.7`ï¼šæ¨¡å‹ä¸ç¢ºå®šçš„é æ¸¬
- `correct = False`ï¼šéœ€è¦é‡é»åˆ†æçš„éŒ¯èª¤æ¨£æœ¬

---

## ğŸ”§ å¸¸ç”¨å‘½ä»¤

```bash
# ç›£æ§è¨“ç·´
tail -f outputs/my_experiment/training.log

# æŸ¥çœ‹æœ€çµ‚æ€§èƒ½
cat outputs/my_experiment/final_metrics.json | jq '.macro_f1'

# è©•ä¼°æ¸¬è©¦é›†
python evaluate.py \
  --ckpt outputs/my_experiment/checkpoints/best.pt \
  --split test \
  --output_dir outputs/my_test

# é æ¸¬æ–°æ•¸æ“š
python predict.py \
  --ckpt outputs/my_experiment/checkpoints/best.pt \
  --input new_sequences.fa \
  --output predictions.csv

# æ‰¾å‡ºéŒ¯èª¤æ¨£æœ¬
grep ",False$" outputs/my_test/test_predictions.csv | head -20

# æ‰¾å‡ºä½ç½®ä¿¡åº¦é æ¸¬
awk -F',' '$6 < 0.7 {print}' outputs/my_test/test_predictions.csv

# æ‰¾å‡ºè¡¨ç¾æœ€å·®çš„é¡åˆ¥
sort -t',' -k5 -n outputs/my_test/test_per_class_metrics.csv | head -10
```

---

## ğŸ“ˆ çµæœåˆ†ææµç¨‹

### æ­¥é©Ÿ 1: æª¢æŸ¥æ•´é«”æ€§èƒ½

```bash
cat outputs/my_test/test_metrics.json | jq '{
  accuracy: .accuracy,
  macro_f1: .macro_f1,
  weighted_f1: .weighted_f1
}'
```

### æ­¥é©Ÿ 2: æ‰¾å‡ºè¡¨ç¾å·®çš„é¡åˆ¥

```bash
cat outputs/my_test/test_per_class_metrics.csv | \
  awk -F',' '$5 < 0.7 {print $1, $5}' | column -t
```

### æ­¥é©Ÿ 3: åˆ†æéŒ¯èª¤æ¨£æœ¬

```bash
grep ",False$" outputs/my_test/test_predictions.csv | \
  awk -F',' '{print $2, "â†’", $3, "(" $6 ")"}' | head -20
```

### æ­¥é©Ÿ 4: æŸ¥çœ‹æ··æ·†çŸ©é™£

```bash
display outputs/my_test/test_confusion_matrix.png
```

---

# å¸¸è¦‹å•é¡Œèˆ‡æ•…éšœæ’é™¤

## ğŸš¨ CUDA Out of Memory

å¦‚æœä»ç„¶å‡ºç¾ OOM éŒ¯èª¤ï¼š

### è§£æ±ºæ–¹æ¡ˆ 1: æ¸›å°‘åºåˆ—é•·åº¦ï¼ˆæœ€æœ‰æ•ˆï¼ï¼‰
```yaml
tokenizer:
  max_length: 64  # å¾ 128 æ¸›å°‘åˆ° 64
```

### è§£æ±ºæ–¹æ¡ˆ 2: å¢åŠ æ¢¯åº¦ç´¯ç©
```yaml
training:
  grad_accum_steps: 16  # å¾ 8 å¢åŠ åˆ° 16
```

### è§£æ±ºæ–¹æ¡ˆ 3: æ›´å°çš„ LoRA rank
```yaml
model:
  lora:
    r: 2  # å¾ 4 æ¸›å°‘åˆ° 2
```

### è§£æ±ºæ–¹æ¡ˆ 4: æ¸›å°‘ target modules
```yaml
model:
  lora:
    target_modules: [q_proj]  # åªç”¨ä¸€å€‹
```

---

## â±ï¸ è¨“ç·´é€Ÿåº¦å¤ªæ…¢

### è§£æ±ºæ–¹æ¡ˆ 1: ä½¿ç”¨è³‡æ–™å­é›†
```bash
# å‰µå»ºå°å‹æ¸¬è©¦é›†
head -n 10000000 train.fa > train_mini.fa
```

### è§£æ±ºæ–¹æ¡ˆ 2: æ¸›å°‘ epochs
```bash
python train.py ... --max_epochs 3
```

### è§£æ±ºæ–¹æ¡ˆ 3: å¢åŠ  batch sizeï¼ˆå¦‚æœè¨˜æ†¶é«”å…è¨±ï¼‰
```yaml
training:
  batch_size: 2
  grad_accum_steps: 4
```

---

## ğŸ“Š åˆ¤æ–·è¨“ç·´æ˜¯å¦éæ“¬åˆ

æŸ¥çœ‹ `plots/training_curves.png`ï¼š

- âœ… **æ­£å¸¸**ï¼šTrain Loss å’Œ Val Loss éƒ½ä¸‹é™
- âš ï¸ **è¼•åº¦éæ“¬åˆ**ï¼šVal Loss ä¸å†ä¸‹é™ï¼ŒTrain Loss ç¹¼çºŒä¸‹é™
- ğŸš« **åš´é‡éæ“¬åˆ**ï¼šVal Loss é–‹å§‹ä¸Šå‡ï¼ŒTrain Loss æŒçºŒä¸‹é™

**è§£æ±ºéæ“¬åˆ**ï¼š
- å¢åŠ  dropout
- å¢åŠ  weight_decay
- ä½¿ç”¨ label_smoothing
- å•Ÿç”¨ early stopping

---

## ğŸ¯ Confidence åˆ†æ•¸è§£è®€

- `> 0.9`ï¼šé«˜ç½®ä¿¡åº¦ï¼Œé€šå¸¸æ­£ç¢º
- `0.7-0.9`ï¼šä¸­ç­‰ç½®ä¿¡åº¦ï¼Œå¤§å¤šæ­£ç¢º
- `< 0.7`ï¼šä½ç½®ä¿¡åº¦ï¼Œ**å»ºè­°äººå·¥å¾©æ ¸**
- `< 0.5`ï¼šéå¸¸ä¸ç¢ºå®šï¼Œ**é«˜é¢¨éšªé æ¸¬**

---

## ğŸ’¾ å¿…é ˆå‚™ä»½çš„æª”æ¡ˆ

1. **`checkpoints/best.pt`** (13GB) - **æœ€é‡è¦ï¼**
2. **`config.json`** (2KB)
3. **`final_model/`** ç›®éŒ„ (~100KB)
4. **`species_mapping_converted.tsv`** (åŸå§‹æ˜ å°„æª”æ¡ˆ)

---

## ğŸ“š æ›´å¤šè³‡æº

- **README.md** - å°ˆæ¡ˆæ•´é«”èªªæ˜
- **DEVELOPER_GUIDE.md** - é€²éšé…ç½®å’Œè¶…åƒæ•¸èª¿æ•´
- **configs/rtx4090_optimized.yaml** - RTX 4090 é…ç½®æª”æ¡ˆ
- **configs/default.yaml** - æ¨™æº–é…ç½®æª”æ¡ˆ

---

**æœ€å¾Œæ›´æ–°**: 2025-11-10  
**ç‰ˆæœ¬**: 2.0 (æ•´åˆç‰ˆ)

