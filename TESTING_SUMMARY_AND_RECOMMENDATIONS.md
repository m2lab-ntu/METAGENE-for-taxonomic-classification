# METAGENE Classification æ¸¬è©¦ç¸½çµèˆ‡å»ºè­°

## ğŸ“‹ æ¸¬è©¦æ—¥æœŸ
2025-11-02

## âœ… æˆåŠŸå®Œæˆçš„é …ç›®

### 1. æ¨¡å‹ä¸‹è¼‰ âœ“
- **ç‹€æ…‹**ï¼šæˆåŠŸ
- **ä½ç½®**ï¼š`/media/user/disk2/.cache/huggingface/`
- **å¤§å°**ï¼šç´„ 16GB
- **è§£æ±ºæ–¹æ¡ˆ**ï¼š
  - å°‡ HuggingFace cache ç§»è‡³ `/media/user/disk2`ï¼ˆæœ‰è¶³å¤ ç©ºé–“ï¼‰
  - è¨­ç½®ç’°å¢ƒè®Šæ•¸ï¼š
    ```bash
    export HF_HOME=/media/user/disk2/.cache/huggingface
    export TRANSFORMERS_CACHE=/media/user/disk2/.cache/huggingface
    ```

### 2. Data Loading Pipeline âœ“
- **ç‹€æ…‹**ï¼šå®Œå…¨æ­£å¸¸
- **æ¸¬è©¦çµæœ**ï¼š
  ```
  âœ“ Tokenizer è¼‰å…¥
  âœ“ FASTA æª”æ¡ˆè§£æ
  âœ“ Label mapping
  âœ“ DataLoader æ‰¹æ¬¡è™•ç†
  âœ“ è¨“ç·´/é©—è­‰ dataset å»ºç«‹
  ```
- **æ¸¬è©¦è…³æœ¬**ï¼š`test_dataloader_only.py`

### 3. HuggingFace Tokenizer æ•´åˆ âœ“
- **ç‹€æ…‹**ï¼šæˆåŠŸæ•´åˆ
- **æ”¹é€²**ï¼š
  - æ”¯æ´ minbpe tokenizerï¼ˆåŸæœ‰ï¼‰
  - æ”¯æ´ HuggingFace å®˜æ–¹ tokenizerï¼ˆæ–°å¢ï¼Œæ¨è–¦ï¼‰
  - å¯é€šéé…ç½®åˆ‡æ›ï¼š`use_hf_tokenizer: true`
- **Vocab size**ï¼š1024 tokensï¼ˆæ­£ç¢ºåŒ¹é…æ¨¡å‹ï¼‰

### 4. ä»£ç¢¼ä¿®æ”¹èˆ‡å„ªåŒ– âœ“
- **æ¨¡å‹è¼‰å…¥**ï¼šæ·»åŠ  `device_map="auto"` ç¬¦åˆ HF å»ºè­°
- **Tokenizer å…¼å®¹æ€§**ï¼šæ”¯æ´é›™æ¨¡å¼ï¼ˆminbpe + HFï¼‰
- **è¨“ç·´è…³æœ¬ä¿®å¾©**ï¼š
  - ä¿®æ­£ batch éæ¿¾ï¼ˆç§»é™¤ metadataï¼‰
  - ä¿®æ­£ learning rate æ ¼å¼
  - æ·»åŠ  HF tokenizer æ”¯æ´

### 5. é…ç½®æª”æ¡ˆ âœ“
- `configs/default.yaml` - minbpe tokenizer
- `configs/default_hf_tokenizer.yaml` - HuggingFace tokenizerï¼ˆæ¨è–¦ï¼‰

## âŒ é‡åˆ°çš„é™åˆ¶

### GPU è¨˜æ†¶é«”ä¸è¶³ (Critical Issue)

**å•é¡Œ**ï¼š
```
torch.OutOfMemoryError: CUDA out of memory
GPU 0 has a total capacity of 23.64 GiB
```

**æ¸¬è©¦çµæœ**ï¼š
| Batch Size | Max Length | Status | GPU ä½¿ç”¨ |
|-----------|------------|--------|----------|
| 128 | 512 | âŒ OOM | N/A |
| 2 | 512 | âŒ OOM | 22.8GB |
| 1 | 512 | âŒ OOM | 22.9GB |

**åŸå› åˆ†æ**ï¼š
1. **æ¨¡å‹å¤§å°**ï¼šMETAGENE-1 = 7B åƒæ•¸
2. **è¨˜æ†¶é«”ä½”ç”¨**ï¼ˆbf16 precisionï¼‰ï¼š
   - æ¨¡å‹æ¬Šé‡ï¼š~14GB
   - Activationsï¼ˆå‰å‘å‚³æ’­ï¼‰ï¼š~8GB
   - Gradientsï¼ˆåå‘å‚³æ’­ï¼‰ï¼š~2GB
   - Optimizer statesï¼š~4GB
   - **ç¸½è¨ˆ**ï¼š~28GBï¼ˆè¶…é RTX 4090 çš„ 24GBï¼‰

3. **å³ä½¿ä½¿ç”¨ LoRA**ï¼š
   - LoRA åªè¨“ç·´ 8.4M åƒæ•¸ï¼ˆ0.13%ï¼‰
   - ä½†åŸºç¤æ¨¡å‹ä»éœ€è¼‰å…¥ä¸¦ä¿å­˜ activations
   - ç¯€çœçš„ä¸»è¦æ˜¯ gradient å’Œ optimizer memory
   - ä»ç„¶éœ€è¦ç´„ 22-23GB

## ğŸ’¡ è§£æ±ºæ–¹æ¡ˆèˆ‡å»ºè­°

### æ–¹æ¡ˆ 1ï¼šä½¿ç”¨æ›´å¤§çš„ GPUï¼ˆæ¨è–¦ï¼‰

**éœ€æ±‚**ï¼š
- **GPU**ï¼š40GB+ VRAM
  - NVIDIA A100 (40GB/80GB)
  - NVIDIA A6000 (48GB)
  - H100 (80GB)

**é æœŸçµæœ**ï¼š
- Batch size: 8-16
- Training time: 2-4 hoursï¼ˆ10k sequencesï¼‰
- å®Œå…¨æ”¯æ´çš„é…ç½®

### æ–¹æ¡ˆ 2ï¼šå¤š GPU è¨“ç·´

**ä½¿ç”¨ PyTorch DDP/FSDP**ï¼š
```bash
# 2x RTX 4090 (48GB total)
torchrun --nproc_per_node=2 train.py \
  --config configs/default.yaml \
  ... 
```

**ä¿®æ”¹éœ€æ±‚**ï¼š
- æ·»åŠ åˆ†æ•£å¼è¨“ç·´æ”¯æ´åˆ° `train.py`
- ä½¿ç”¨ FSDP (Fully Sharded Data Parallel)

### æ–¹æ¡ˆ 3ï¼šä½¿ç”¨é‡åŒ–ï¼ˆQLoRAï¼‰

**8-bit/4-bit é‡åŒ–**ï¼š
```python
from transformers import BitsAndBytesConfig

bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_quant_type="nf4"
)

model = AutoModel.from_pretrained(
    "metagene-ai/METAGENE-1",
    quantization_config=bnb_config
)
```

**é æœŸç¯€çœ**ï¼š
- 4-bitï¼šæ¨¡å‹è¨˜æ†¶é«”æ¸›å°‘è‡³ ~3.5GB
- å¯èƒ½æ”¯æ´ batch_size=4-8 on RTX 4090

**æ¬Šè¡¡**ï¼š
- è¼•å¾®æº–ç¢ºåº¦é™ä½ï¼ˆé€šå¸¸ <1%ï¼‰
- è¨“ç·´é€Ÿåº¦ç¨æ…¢

### æ–¹æ¡ˆ 4ï¼šGradient Checkpointing

**å•Ÿç”¨ gradient checkpointing**ï¼š
```python
model.encoder.gradient_checkpointing_enable()
```

**æ•ˆæœ**ï¼š
- æ¸›å°‘ activation memory ~50%
- è¨“ç·´é€Ÿåº¦é™ä½ ~20%
- å¯èƒ½æ”¯æ´ batch_size=2-4

### æ–¹æ¡ˆ 5ï¼šä½¿ç”¨é›²ç«¯ GPU

**æ¨è–¦æœå‹™**ï¼š
- **Google Colab Pro+**ï¼šA100 40GBï¼ˆ$50/monthï¼‰
- **AWS EC2**ï¼šp4d.24xlarge (8x A100)
- **Lambda Labs**ï¼šA100 $1.10/hour
- **Vast.ai**ï¼šä¾¿å®œçš„ A100 ç§Ÿç”¨

## ğŸ”§ ç«‹å³å¯ç”¨çš„è®Šé€šæ–¹æ³•

### é¸é … Aï¼šåƒ…æ¸¬è©¦æ¨ç†ï¼ˆInference Onlyï¼‰

å¦‚æœåªéœ€è¦æ¸¬è©¦æ¨ç†è€Œä¸è¨“ç·´ï¼š

```bash
# ä½¿ç”¨é è¨“ç·´æ¨¡å‹é€²è¡Œç‰¹å¾µæå–
python predict.py \
  --input test_reads.fa \
  --ckpt metagene-ai/METAGENE-1 \
  --output predictions.csv \
  --batch_size 16
```

**è¨˜æ†¶é«”éœ€æ±‚**ï¼š
- Inference onlyï¼š~14GBï¼ˆå¯è¡Œï¼‰
- æ”¯æ´ batch_size=16-32

### é¸é … Bï¼šå‡çµæ›´å¤šå±¤

```yaml
model:
  lora:
    enabled: true
    target_modules: [q_proj, v_proj]  # åªè¨“ç·´ Q å’Œ V
    r: 4  # æ¸›å°‘ LoRA rank
```

**æ•ˆæœæœ‰é™**ï¼šä¸»è¦ç“¶é ¸åœ¨ activationsï¼Œä¸åœ¨ trainable parameters

### é¸é … Cï¼šæ¸›å°‘åºåˆ—é•·åº¦

```yaml
tokenizer:
  max_length: 256  # å¾ 512 æ¸›å°‘åˆ° 256
```

**é ä¼°**ï¼š
- è¨˜æ†¶é«”æ¸›å°‘ ~30%
- å¯èƒ½æ”¯æ´ batch_size=2
- **æ¬Šè¡¡**ï¼šé•·åºåˆ—æœƒè¢«æˆªæ–·

##  ğŸ“Š ç¡¬é«”éœ€æ±‚ç¸½çµ

| è¨“ç·´å ´æ™¯ | GPU éœ€æ±‚ | Batch Size | Training Time |
|----------|---------|-----------|---------------|
| **Full Training** | 40GB+ | 8-16 | 2-4 hours |
| **4-bit QLoRA** | 24GB | 4-8 | 3-6 hours |
| **Gradient Checkpoint** | 24GB | 2-4 | 4-8 hours |
| **Inference Only** | 24GB | 16-32 | N/A |
| **ç•¶å‰ RTX 4090** | 24GB | âŒ 0-1 | âŒ ç„¡æ³•è¨“ç·´ |

## ğŸ¯ å»ºè­°çš„ä¸‹ä¸€æ­¥

### ç«‹å³è¡Œå‹•ï¼ˆä¸éœ€æ›´æ›ç¡¬é«”ï¼‰ï¼š

1. **æ¸¬è©¦æ¨ç†åŠŸèƒ½**ï¼š
   ```bash
   # æ¸¬è©¦ feature extraction
   python predict.py --input your_data.fa --ckpt metagene-ai/METAGENE-1
   ```

2. **å¯¦ä½œ QLoRA**ï¼š
   - ä¿®æ”¹ `modeling.py` æ·»åŠ é‡åŒ–æ”¯æ´
   - å¯èƒ½åœ¨ RTX 4090 ä¸Šè¨“ç·´

3. **ä½¿ç”¨é›²ç«¯GPU**ï¼š
   - ç§Ÿç”¨ A100 å®Œæˆè¨“ç·´
   - è²»ç”¨ï¼šç´„ $10-20ï¼ˆ4-8å°æ™‚è¨“ç·´ï¼‰

### é•·æœŸè§£æ±ºæ–¹æ¡ˆï¼š

1. **å‡ç´šç¡¬é«”**ï¼šA100 40GB/80GB
2. **å¤šGPUè¨­ç½®**ï¼š2-4x RTX 4090
3. **ä½¿ç”¨è¼ƒå°æ¨¡å‹**ï¼šå¦‚æœå­˜åœ¨ 1B-3B ç‰ˆæœ¬çš„ METAGENE

## ğŸ“ ç’°å¢ƒè¨­ç½®è…³æœ¬

ç‚ºäº†æ–¹ä¾¿æœªä¾†ä½¿ç”¨ï¼Œå‰µå»ºå¿«é€Ÿè¨­ç½®è…³æœ¬ï¼š

```bash
#!/bin/bash
# setup_metagene_env.sh

# è¨­ç½® HuggingFace cache
export HF_HOME=/media/user/disk2/.cache/huggingface
export TRANSFORMERS_CACHE=/media/user/disk2/.cache/huggingface

# è¨­ç½® CUDA è¨˜æ†¶é«”åˆ†é…
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

# æ¿€æ´»ç’°å¢ƒ
conda activate METAGENE

echo "Environment ready for METAGENE classification"
```

## ğŸ çµè«–

**æˆåŠŸé …ç›®**ï¼š
- âœ… å®Œæ•´çš„ classification pipeline å·²å¯¦ä½œ
- âœ… HuggingFace æ•´åˆå®Œæˆ
- âœ… Data loading å®Œå…¨æ­£å¸¸
- âœ… æ¨¡å‹å·²ä¸‹è¼‰ä¸¦å¯ç”¨

**ä¸»è¦é™åˆ¶**ï¼š
- âŒ RTX 4090 24GB ç„¡æ³•è¨“ç·´ METAGENE-1 7B
- âš ï¸ éœ€è¦ 40GB+ GPU æˆ–ä½¿ç”¨é‡åŒ–æŠ€è¡“

**æ¨è–¦æ–¹æ¡ˆ**ï¼š
1. ğŸ¥‡ ä½¿ç”¨é›²ç«¯ A100 GPU å®Œæˆè¨“ç·´
2. ğŸ¥ˆ å¯¦ä½œ 4-bit QLoRA åœ¨ RTX 4090 ä¸Šè¨“ç·´
3. ğŸ¥‰ ä½¿ç”¨ç•¶å‰ç¡¬é«”é€²è¡Œæ¨ç†æ¸¬è©¦

---

**æœ€å¾Œæ›´æ–°**ï¼š2025-11-02
**æ¸¬è©¦äººå“¡**ï¼šAI Assistant
**GPU**ï¼šNVIDIA RTX 4090 (24GB)
**Status**ï¼šâœ… Pipeline Ready | âŒ Training Blocked (OOM)

