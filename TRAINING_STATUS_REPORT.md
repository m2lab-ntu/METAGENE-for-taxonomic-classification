# 訓練狀態報告 - 2025-11-18

## 當前狀況

### ❌ 兩次訓練嘗試都失敗

#### 嘗試 1: 原始實現 (15:17 - 16:55)
- **方法**: 將所有序列載入內存
- **運行時間**: 1 小時 38 分鐘
- **內存消耗**: 達到 6.5 GB 並持續增長
- **結果**: 手動停止（預計還需 3-5 小時）
- **原因**: 數據載入效率太低

#### 嘗試 2: 優化版本 - IndexedFastaDataset (17:03 - 17:38)
- **方法**: 建立文件索引，按需載入
- **運行時間**: 35 分鐘
- **內存消耗**: 達到 3.4 GB
- **結果**: 進程被殺 (Killed) - OOM
- **原因**: 建立 5.58 億條序列的索引本身需要數 GB 內存

## 根本問題

### 數據規模
- **訓練文件**: 100 GB, 5.58 億條序列
- **驗證文件**: 預計類似規模
- **物種數**: 3507

### 內存限制
系統內存無法容納：
1. 所有序列數據 (需要 20-30 GB)
2. 所有序列的索引 (需要 3-5 GB)
3. 模型和訓練狀態 (需要 10-15 GB)

## 可行解決方案

### 方案 A: 創建訓練數據子集 ⭐ (推薦)

創建較小但代表性的訓練集：

**選項 A1: 中等規模 (推薦)**
- 每個物種: 10,000 條序列
- 總序列數: 35,070,000 (3507 物種 × 10,000)
- 預估大小: ~6-8 GB
- 內存需求: ~2-3 GB 數據 + 5-10 GB 模型
- 優點: 快速訓練，足夠的數據量
- 缺點: 不是完整數據集

**選項 A2: 小規模 (快速測試)**
- 每個物種: 1,000 條序列
- 總序列數: 3,507,000
- 預估大小: ~600-800 MB
- 優點: 非常快速
- 缺點: 可能影響最終性能

**選項 A3: 大規模**
- 每個物種: 50,000 條序列
- 總序列數: 175,350,000
- 預估大小: ~30-35 GB
- 優點: 接近完整數據
- 缺點: 仍可能內存不足

### 方案 B: 使用真正的流式處理

重新實現為 IterableDataset：
- 不建立索引
- 順序讀取文件
- 不支持完全隨機 shuffling
- 可以在 epoch 級別 shuffle

**優點:**
- 零內存佔用（數據部分）
- 可以處理任意大小數據集

**缺點:**
- 不支持完全隨機訪問
- 可能影響訓練收斂速度

### 方案 C: 使用 HDF5/Zarr 格式

預處理數據轉換為高效二進制格式：
- 一次性轉換（可能需要數小時）
- 訓練時高效隨機訪問
- 支持 shuffling

**優點:**
- 訓練時極快
- 支持所有功能

**缺點:**
- 需要額外存儲空間（~100 GB）
- 預處理時間長

## 建議行動計劃

### 立即行動 (推薦): 方案 A1

1. **創建中等規模訓練集**
   ```bash
   # 從現有數據中採樣
   # 每個物種 10,000 條序列
   ```

2. **優勢**:
   - 可以立即開始訓練
   - 內存完全可控
   - 訓練時間合理（數小時而非數天）
   - 可以快速迭代和調試

3. **後續計劃**:
   - 先用中等規模數據訓練和評估
   - 驗證整個流程正確
   - 如果需要，後續可以：
     - 使用更大數據子集
     - 實現真正的流式處理
     - 轉換為 HDF5 格式

### 保守行動: 方案 B

實現真正的流式 IterableDataset，處理完整數據集。

## 創建訓練數據子集的腳本

需要創建一個腳本：
```python
create_training_subset.py --input train.fa --output train_subset.fa --per_species 10000
```

功能：
- 從每個物種隨機採樣指定數量序列
- 保持標籤分佈平衡
- 輸出小規模訓練集

## 時間估算

### 使用中等規模子集 (10K per species)
- 創建子集: 10-30 分鐘
- 載入數據: 2-5 分鐘
- 訓練 METAGENE: 2-4 小時
- 訓練 DNABERT: 2-4 小時
- **總時間: 4-8 小時**

### 使用完整數據集 + 流式處理
- 實現流式載入器: 30-60 分鐘
- 訓練 METAGENE: 8-12 小時
- 訓練 DNABERT: 8-12 小時
- **總時間: 16-24 小時**

## 決策

**推薦**: 採用方案 A1 - 創建中等規模訓練子集

這樣可以：
1. ✅ 立即開始訓練
2. ✅ 避免內存問題
3. ✅ 合理的訓練時間
4. ✅ 驗證整個流程
5. ✅ 獲得有意義的 benchmark 結果

如果後續需要完整數據集訓練，可以再實現流式處理或數據格式轉換。

