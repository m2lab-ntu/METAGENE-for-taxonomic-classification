#!/usr/bin/env python3
"""
å¾å¤§å‹è¨“ç·´æ–‡ä»¶ä¸­å‰µå»ºå­é›†ï¼Œæ¯å€‹ç‰©ç¨®æ¡æ¨£æŒ‡å®šæ•¸é‡çš„åºåˆ—ã€‚
ä½¿ç”¨æµå¼è™•ç†ä»¥é¿å…å…§å­˜å•é¡Œã€‚
"""

import argparse
import sys
from pathlib import Path
from collections import defaultdict
import random


def sample_fasta_by_species(input_fasta, output_fasta, per_species, seed=42):
    """
    å¾ FASTA æ–‡ä»¶ä¸­æŒ‰ç‰©ç¨®æ¡æ¨£åºåˆ—ã€‚
    
    ç­–ç•¥ï¼š
    1. ç¬¬ä¸€éï¼šçµ±è¨ˆæ¯å€‹ç‰©ç¨®çš„åºåˆ—æ•¸é‡
    2. ç¬¬äºŒéï¼šæŒ‰æ¯”ä¾‹æ¡æ¨£ï¼ˆreservoir samplingï¼‰
    
    Args:
        input_fasta: è¼¸å…¥ FASTA æ–‡ä»¶è·¯å¾‘
        output_fasta: è¼¸å‡º FASTA æ–‡ä»¶è·¯å¾‘
        per_species: æ¯å€‹ç‰©ç¨®æ¡æ¨£çš„åºåˆ—æ•¸é‡
        seed: éš¨æ©Ÿç¨®å­
    """
    random.seed(seed)
    
    print(f"ğŸ“Š ç¬¬ä¸€éï¼šçµ±è¨ˆæ¯å€‹ç‰©ç¨®çš„åºåˆ—æ•¸é‡...")
    print(f"è¼¸å…¥æ–‡ä»¶: {input_fasta}")
    
    # ç¬¬ä¸€éï¼šçµ±è¨ˆæ¯å€‹ç‰©ç¨®æœ‰å¤šå°‘åºåˆ—
    species_counts = defaultdict(int)
    total_sequences = 0
    
    with open(input_fasta, 'r') as f:
        for line in f:
            if line.startswith('>'):
                # è§£æ header: >lbl|class_id|...
                parts = line[1:].strip().split('|')
                if len(parts) >= 2:
                    try:
                        class_id = int(parts[1])
                        species_counts[class_id] += 1
                        total_sequences += 1
                        
                        if total_sequences % 10000000 == 0:
                            print(f"  å·²çµ±è¨ˆ {total_sequences:,} æ¢åºåˆ—...")
                    except (ValueError, IndexError):
                        pass
    
    num_species = len(species_counts)
    print(f"\nâœ… çµ±è¨ˆå®Œæˆ:")
    print(f"  ç¸½åºåˆ—æ•¸: {total_sequences:,}")
    print(f"  ç‰©ç¨®æ•¸: {num_species}")
    print(f"  å¹³å‡æ¯ç‰©ç¨®: {total_sequences // num_species:,} æ¢åºåˆ—")
    
    # è¨ˆç®—æ¡æ¨£ç­–ç•¥
    print(f"\nğŸ¯ æ¡æ¨£ç­–ç•¥:")
    species_to_sample = {}
    species_with_fewer_seqs = 0
    
    for class_id, count in species_counts.items():
        if count <= per_species:
            species_to_sample[class_id] = count  # å…¨éƒ¨æ¡æ¨£
            species_with_fewer_seqs += 1
        else:
            species_to_sample[class_id] = per_species  # æ¡æ¨£æŒ‡å®šæ•¸é‡
    
    total_output_sequences = sum(species_to_sample.values())
    
    print(f"  ç›®æ¨™æ¯ç‰©ç¨®: {per_species:,} æ¢åºåˆ—")
    print(f"  åºåˆ—æ•¸ < {per_species} çš„ç‰©ç¨®: {species_with_fewer_seqs}")
    print(f"  é æœŸè¼¸å‡ºç¸½åºåˆ—æ•¸: {total_output_sequences:,}")
    print(f"  å£“ç¸®ç‡: {total_output_sequences / total_sequences * 100:.1f}%")
    
    # ç¬¬äºŒéï¼šæ¡æ¨£åºåˆ—
    print(f"\nğŸ“ ç¬¬äºŒéï¼šæ¡æ¨£ä¸¦å¯«å…¥åºåˆ—...")
    
    # ä½¿ç”¨ reservoir sampling ç®—æ³•
    # ç‚ºæ¯å€‹ç‰©ç¨®ç¶­è­·ä¸€å€‹ reservoir
    reservoirs = {class_id: [] for class_id in species_counts.keys()}
    current_counts = defaultdict(int)
    
    sequences_read = 0
    with open(input_fasta, 'r') as f:
        current_header = None
        current_class_id = None
        
        for line in f:
            if line.startswith('>'):
                # æ–°çš„åºåˆ—
                current_header = line
                parts = line[1:].strip().split('|')
                
                if len(parts) >= 2:
                    try:
                        current_class_id = int(parts[1])
                        sequences_read += 1
                        
                        if sequences_read % 10000000 == 0:
                            print(f"  å·²è™•ç† {sequences_read:,} / {total_sequences:,} åºåˆ— ({sequences_read/total_sequences*100:.1f}%)")
                    except (ValueError, IndexError):
                        current_class_id = None
            else:
                # åºåˆ—è¡Œ
                if current_class_id is not None and current_header is not None:
                    sequence = line
                    current_counts[current_class_id] += 1
                    k = species_to_sample[current_class_id]
                    
                    # Reservoir sampling
                    if len(reservoirs[current_class_id]) < k:
                        # Reservoir é‚„æ²’æ»¿ï¼Œç›´æ¥æ·»åŠ 
                        reservoirs[current_class_id].append((current_header, sequence))
                    else:
                        # Reservoir å·²æ»¿ï¼Œéš¨æ©Ÿæ›¿æ›
                        j = random.randint(0, current_counts[current_class_id] - 1)
                        if j < k:
                            reservoirs[current_class_id][j] = (current_header, sequence)
                    
                    current_header = None
                    current_class_id = None
    
    print(f"\nğŸ’¾ å¯«å…¥è¼¸å‡ºæ–‡ä»¶: {output_fasta}")
    
    # å¯«å…¥æ¡æ¨£çš„åºåˆ—
    sequences_written = 0
    with open(output_fasta, 'w') as f:
        for class_id in sorted(reservoirs.keys()):
            for header, sequence in reservoirs[class_id]:
                f.write(header)
                f.write(sequence)
                sequences_written += 1
                
                if sequences_written % 1000000 == 0:
                    print(f"  å·²å¯«å…¥ {sequences_written:,} / {total_output_sequences:,} åºåˆ—")
    
    print(f"\nâœ… å®Œæˆ!")
    print(f"  è¼¸å‡ºæ–‡ä»¶: {output_fasta}")
    print(f"  å¯¦éš›å¯«å…¥åºåˆ—æ•¸: {sequences_written:,}")
    
    # é¡¯ç¤ºæ¡æ¨£çµ±è¨ˆ
    print(f"\nğŸ“ˆ æ¡æ¨£çµ±è¨ˆ:")
    sampled_per_species = defaultdict(int)
    for class_id, samples in reservoirs.items():
        sampled_per_species[class_id] = len(samples)
    
    print(f"  æœ€å°æ¯ç‰©ç¨®: {min(sampled_per_species.values()):,}")
    print(f"  æœ€å¤§æ¯ç‰©ç¨®: {max(sampled_per_species.values()):,}")
    print(f"  å¹³å‡æ¯ç‰©ç¨®: {sum(sampled_per_species.values()) // len(sampled_per_species):,}")


def main():
    parser = argparse.ArgumentParser(
        description="å¾å¤§å‹è¨“ç·´æ–‡ä»¶å‰µå»ºå­é›†ï¼ˆæµå¼è™•ç†ï¼Œä½å…§å­˜ï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # æ¯å€‹ç‰©ç¨®æ¡æ¨£ 10,000 æ¢åºåˆ—
  %(prog)s -i train.fa -o train_10k.fa -n 10000
  
  # æ¯å€‹ç‰©ç¨®æ¡æ¨£ 1,000 æ¢åºåˆ—ï¼ˆå¿«é€Ÿæ¸¬è©¦ï¼‰
  %(prog)s -i train.fa -o train_1k.fa -n 1000
  
  # æ¯å€‹ç‰©ç¨®æ¡æ¨£ 50,000 æ¢åºåˆ—ï¼ˆå¤§è¦æ¨¡ï¼‰
  %(prog)s -i train.fa -o train_50k.fa -n 50000
        """
    )
    
    parser.add_argument('-i', '--input', required=True,
                        help='è¼¸å…¥ FASTA æ–‡ä»¶')
    parser.add_argument('-o', '--output', required=True,
                        help='è¼¸å‡º FASTA æ–‡ä»¶')
    parser.add_argument('-n', '--per-species', type=int, required=True,
                        help='æ¯å€‹ç‰©ç¨®æ¡æ¨£çš„åºåˆ—æ•¸é‡')
    parser.add_argument('--seed', type=int, default=42,
                        help='éš¨æ©Ÿç¨®å­ (default: 42)')
    
    args = parser.parse_args()
    
    # æª¢æŸ¥è¼¸å…¥æ–‡ä»¶
    input_path = Path(args.input)
    if not input_path.exists():
        print(f"âŒ éŒ¯èª¤: è¼¸å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}", file=sys.stderr)
        sys.exit(1)
    
    # æª¢æŸ¥è¼¸å‡ºæ–‡ä»¶
    output_path = Path(args.output)
    if output_path.exists():
        response = input(f"âš ï¸  è¼¸å‡ºæ–‡ä»¶å·²å­˜åœ¨: {args.output}\næ˜¯å¦è¦†è“‹? (yes/no): ")
        if response.lower() != 'yes':
            print("å–æ¶ˆæ“ä½œ")
            sys.exit(0)
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    print("="*60)
    print("ğŸ”¬ å‰µå»ºè¨“ç·´æ•¸æ“šå­é›†")
    print("="*60)
    
    try:
        sample_fasta_by_species(
            input_fasta=args.input,
            output_fasta=args.output,
            per_species=args.per_species,
            seed=args.seed
        )
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ¶ä¸­æ–·")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ éŒ¯èª¤: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

