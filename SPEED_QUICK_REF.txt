╔═══════════════════════════════════════════════════════════════════════════════╗
║                    METAGENE 訓練速度調優快速參考                                  ║
╚═══════════════════════════════════════════════════════════════════════════════╝

┌───────────────────────────────────────────────────────────────────────────────┐
│ 🚀 最有效的加速方法（按影響大小排序）                                               │
└───────────────────────────────────────────────────────────────────────────────┘

  1. ⚡⚡⚡⚡⚡  減少 Epochs              max_epochs: 3     (省 70% 時間)
  2. ⚡⚡⚡⚡⚡  減少訓練數據              500K samples    (省 50% 時間)
  3. ⚡⚡⚡⚡    減少序列長度              max_length: 64  (省 30-40% 時間)
  4. ⚡⚡⚡      減少 Gradient Accum      grad_accum: 4   (省 20-30% 時間)
  5. ⚡⚡        更激進的 Early Stop      patience: 2     (省 10-20% 時間)
  6. ⚡⚡        禁用額外 Metrics          各種 false      (省 10-15% 時間)
  7. ⚡         增加 Batch Size          batch_size: 2   (省 15-25% 時間)*
  8. ⚡         減少 Logging             log_interval↑   (省 <5% 時間)

  * 需要測試是否會 OOM

┌───────────────────────────────────────────────────────────────────────────────┐
│ 📊 預設訓練配置對比                                                              │
└───────────────────────────────────────────────────────────────────────────────┘

  配置                      時間          準確度     命令
  ─────────────────────────────────────────────────────────────────────────────
  原始 (當前運行中)          ~12 天        最高      [已在運行]
  快速訓練                   ~1.5 天       高        bash train_fast.sh
  極速訓練                   ~6 小時       中高      bash train_ultrafast.sh
  測試模式                   ~30 分鐘      -         見 SPEED_TUNING_GUIDE.md

┌───────────────────────────────────────────────────────────────────────────────┐
│ 🎯 推薦行動方案                                                                  │
└───────────────────────────────────────────────────────────────────────────────┘

  選項 A: 停止當前訓練，用快速配置重跑
  ─────────────────────────────────────────────────────────────────────────
    1. 停止當前訓練:
       ps aux | grep "python train.py"
       kill <PID>

    2. 創建快速數據集 (可選，推薦):
       ./create_manageable_dataset.sh 500000 125000

    3. 開始快速訓練:
       bash train_fast.sh

    預計完成時間: 1-1.5 天
    預計準確度: 與當前類似（略低）

  ─────────────────────────────────────────────────────────────────────────

  選項 B: 繼續當前訓練
  ─────────────────────────────────────────────────────────────────────────
    - 優點: 最高準確度，無需重跑
    - 缺點: 還需 ~10 天完成
    - 建議: 已運行 3 天，建議繼續

  ─────────────────────────────────────────────────────────────────────────

  選項 C: 兩者並行
  ─────────────────────────────────────────────────────────────────────────
    - 讓當前訓練繼續在後台運行
    - 同時用極速配置在 CPU 或另一個 GPU 測試
    - 注意: 需要足夠的系統資源

┌───────────────────────────────────────────────────────────────────────────────┐
│ ⚙️  關鍵參數修改位置                                                             │
└───────────────────────────────────────────────────────────────────────────────┘

  configs/fast_training.yaml (已創建 ✓)
  ────────────────────────────────────────────────────────
    tokenizer.max_length: 64          # 從 128 降低
    training.max_epochs: 3            # 從 10 降低
    training.grad_accum_steps: 4      # 從 8 降低
    training.early_stopping.patience: 2   # 從 3 降低
    metrics.compute_auroc: false      # 關閉
    metrics.confusion_matrix: false   # 關閉
    logging.log_interval: 10          # 從 5 增加

┌───────────────────────────────────────────────────────────────────────────────┐
│ 📈 監控與檢查                                                                    │
└───────────────────────────────────────────────────────────────────────────────┘

  查看當前訓練進度:
    bash monitor_training.sh

  查看當前訓練速度:
    tail -f outputs/*/training.log | grep "it/s"

  查看序列長度分佈 (決定 max_length):
    head -1000 train_reads_shuffled_fixed.fa | grep "readlen" | \
      awk -F'|' '{print $4}' | sort -n | uniq -c

  檢查 GPU 記憶體:
    nvidia-smi

┌───────────────────────────────────────────────────────────────────────────────┐
│ 💡 建議                                                                         │
└───────────────────────────────────────────────────────────────────────────────┘

  1. 已運行 3 天 (44% of Epoch 1): 
     建議停止並用快速配置重跑，總時間會更短

  2. 如果追求最高準確度:
     讓當前訓練繼續，但考慮修改為 max_epochs=5

  3. 如果想快速迭代:
     用 train_ultrafast.sh 測試不同超參數組合

  4. 數據量建議:
     - 測試: 10K-100K
     - 開發: 100K-500K
     - 生產: 1M+

┌───────────────────────────────────────────────────────────────────────────────┐
│ 📚 詳細文檔                                                                      │
└───────────────────────────────────────────────────────────────────────────────┘

  完整調優指南:     SPEED_TUNING_GUIDE.md
  使用者指南:       USER_GUIDE.md
  開發者指南:       DEVELOPER_GUIDE.md
  超參數快速參考:   HYPERPARAMETERS_QUICK_REF.txt

╔═══════════════════════════════════════════════════════════════════════════════╗
║ 最後更新: 2025-11-10                                                           ║
╚═══════════════════════════════════════════════════════════════════════════════╝

