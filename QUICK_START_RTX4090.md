# å¿«é€Ÿé–‹å§‹ï¼šRTX 4090 ä¸Šè¨“ç·´ METAGENE Classification

## âœ… å·²é©—è­‰å¯è¡Œï¼

RTX 4090 (24GB) å¯ä»¥æˆåŠŸè¨“ç·´ METAGENE-1 (7B) - **å³°å€¼è¨˜æ†¶é«”ä½¿ç”¨ï¼š13GB**

## ğŸš€ ä¸‰æ­¥é©Ÿé–‹å§‹è¨“ç·´

### æ­¥é©Ÿ 1ï¼šè¨­ç½®ç’°å¢ƒ

```bash
cd /media/user/disk2/METAGENE/classification
source setup_env.sh
```

### æ­¥é©Ÿ 2ï¼šæ¸¬è©¦ï¼ˆå¯é¸ï¼‰

```bash
# ç”¨ç¯„ä¾‹è³‡æ–™æ¸¬è©¦ (~3åˆ†é˜)
bash test_optimized_training.sh
```

### æ­¥é©Ÿ 3ï¼šè¨“ç·´ä½ çš„è³‡æ–™

```bash
python train.py \
  --config configs/rtx4090_optimized.yaml \
  --train_fasta YOUR_TRAIN.fa \
  --val_fasta YOUR_VAL.fa \
  --mapping_tsv YOUR_MAPPING.tsv \
  --output_dir outputs/my_experiment \
  --max_epochs 10
```

## ğŸ“ å®Œæ•´ç¯„ä¾‹ï¼šè¨“ç·´ Species Classification

```bash
# è¨­ç½®ç’°å¢ƒ
export HF_HOME=/media/user/disk2/.cache/huggingface
export TRANSFORMERS_CACHE=/media/user/disk2/.cache/huggingface
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True,max_split_size_mb:128

# æ¿€æ´»ç’°å¢ƒ
conda activate METAGENE

# æ¸…ç©º GPU è¨˜æ†¶é«”ï¼ˆå¦‚æœä¹‹å‰æœ‰å…¶ä»–ä»»å‹™ï¼‰
python -c "import torch; torch.cuda.empty_cache()"

# é–‹å§‹è¨“ç·´
python train.py \
  --config configs/rtx4090_optimized.yaml \
  --train_fasta /media/user/disk2/full_labeled_species_train_reads/train_reads.fa \
  --val_fasta /media/user/disk2/full_labeled_species_val_reads/val_reads.fa \
  --mapping_tsv /media/user/disk2/MetaTransformer_new_pipeline/myScript/all_available_species_mapping.tab \
  --output_dir outputs/species_classification \
  --batch_size 1 \
  --max_epochs 10 \
  2>&1 | tee training.log
```

## ğŸ›ï¸ é—œéµå„ªåŒ–è¨­ç½®

å„ªåŒ–é…ç½® (`configs/rtx4090_optimized.yaml`) åŒ…å«ï¼š

| åƒæ•¸ | å€¼ | åŸå›  |
|------|-----|------|
| `max_length` | 128 | æ¸›å°‘è¨˜æ†¶é«”ä½¿ç”¨ 60% |
| `batch_size` | 1 | æœ€å°è¨˜æ†¶é«”ä½”ç”¨ |
| `grad_accum_steps` | 8 | ä¿æŒæœ‰æ•ˆ batch=8 |
| `lora.r` | 4 | æ¸›å°‘åƒæ•¸ |
| `lora.target_modules` | [q_proj, v_proj] | åªè¨“ç·´é—œéµæ¨¡çµ„ |
| `gradient_checkpointing` | true | **ç¯€çœ 50% activation memory** |

## ğŸ“Š é æœŸçµæœ

### è¨˜æ†¶é«”ä½¿ç”¨
- **å³°å€¼**: 13GB / 24GB âœ“
- **å¹³å‡**: ~13GB
- **å®‰å…¨é‚Šç•Œ**: 11GB å‰©é¤˜

### è¨“ç·´é€Ÿåº¦
- **å°è³‡æ–™é›†** (1k reads): ~30 åˆ†é˜/10 epochs
- **ä¸­è³‡æ–™é›†** (10k reads): ~5 å°æ™‚/10 epochs
- **å¤§è³‡æ–™é›†** (100k reads): ~50 å°æ™‚/10 epochs

### è¼¸å‡ºæª”æ¡ˆ
```
outputs/YOUR_EXPERIMENT/
â”œâ”€â”€ checkpoints/best.pt          # æœ€ä½³æ¨¡å‹
â”œâ”€â”€ final_model/                 # ç”¨æ–¼æ¨ç†
â”œâ”€â”€ plots/training_curves.png    # è¨“ç·´æ›²ç·š
â””â”€â”€ final_metrics.json           # æœ€çµ‚æŒ‡æ¨™
```

## ğŸ”§ æ•…éšœæ’é™¤

### å•é¡Œ 1ï¼šé‚„æ˜¯ OOMï¼Ÿ

**è§£æ±ºæ–¹æ¡ˆ A**: æ¸›å°‘åºåˆ—é•·åº¦
```bash
python train.py --config configs/rtx4090_optimized.yaml --max_length 64 ...
```

**è§£æ±ºæ–¹æ¡ˆ B**: ä¿®æ”¹é…ç½®ä½¿ç”¨ ultra-safe æ¨¡å¼
```yaml
# åœ¨ configs/rtx4090_optimized.yaml ä¸­
tokenizer:
  max_length: 64
model:
  lora:
    r: 2
    target_modules: [q_proj]
```

### å•é¡Œ 2ï¼šè¨“ç·´å¤ªæ…¢ï¼Ÿ

**è§£æ±ºæ–¹æ¡ˆ**: å˜—è©¦ç¨å¤§çš„ batch size
```yaml
training:
  batch_size: 2  # å¯èƒ½å¯è¡Œ
  grad_accum_steps: 4  # ä¿æŒæœ‰æ•ˆ batch=8
tokenizer:
  max_length: 96  # æ¸›å°‘é•·åº¦ä¾†è£œå„Ÿ
```

### å•é¡Œ 3ï¼šæº–ç¢ºåº¦ä¸å¤ ï¼Ÿ

**è§£æ±ºæ–¹æ¡ˆ A**: å¢åŠ è¨“ç·´æ™‚é–“
```bash
python train.py --config configs/rtx4090_optimized.yaml --max_epochs 20 ...
```

**è§£æ±ºæ–¹æ¡ˆ B**: ä½¿ç”¨æ›´å¤§çš„ LoRA rank
```yaml
model:
  lora:
    r: 8  # å¢åŠ è‡³ 8
    target_modules: [q_proj, k_proj, v_proj, o_proj]  # æ‰€æœ‰æ¨¡çµ„
```
**æ³¨æ„**: é€™æœƒå¢åŠ è¨˜æ†¶é«”ä½¿ç”¨åˆ° ~16-18GB

## ğŸ“ˆ ç›£æ§è¨“ç·´

### æª¢æŸ¥ GPU ä½¿ç”¨
```bash
watch -n 1 nvidia-smi
```

### æŸ¥çœ‹è¨“ç·´ log
```bash
tail -f training.log
```

### å³æ™‚æŸ¥çœ‹æŒ‡æ¨™
```bash
# è¨“ç·´éç¨‹ä¸­
cat outputs/YOUR_EXPERIMENT/final_metrics.json
```

## âš¡ æ€§èƒ½æå‡æŠ€å·§

### 1. ä½¿ç”¨ SSD å­˜å„²è³‡æ–™
ç¢ºä¿è¨“ç·´è³‡æ–™åœ¨å¿«é€Ÿå„²å­˜è£ç½®ä¸Š

### 2. é è™•ç†è³‡æ–™
å¦‚æœè³‡æ–™é›†å¾ˆå¤§ï¼Œè€ƒæ…®é å…ˆ tokenize

### 3. èª¿æ•´ DataLoader workers
```yaml
# åœ¨é…ç½®ä¸­ï¼ˆå¦‚æœæ”¯æ´ï¼‰
dataset:
  num_workers: 4  # æ ¹æ“š CPU æ ¸å¿ƒæ•¸èª¿æ•´
```

### 4. å•Ÿç”¨ç·¨è­¯ï¼ˆå¯¦é©—æ€§ï¼‰
```yaml
training:
  torch_compile: true  # PyTorch 2.0+
```
**è­¦å‘Š**: å¯èƒ½ä¸ç©©å®šï¼Œåƒ…åœ¨ç©©å®šè¨“ç·´å¾Œå˜—è©¦

## ğŸ“– æ›´å¤šè³‡æº

- **è©³ç´°æˆåŠŸå ±å‘Š**: `SUCCESS_RTX4090_TRAINING.md`
- **å®Œæ•´æ¸¬è©¦ç¸½çµ**: `TESTING_SUMMARY_AND_RECOMMENDATIONS.md`
- **Tokenizer æŒ‡å—**: `HUGGINGFACE_TOKENIZER_GUIDE.md`
- **é…ç½®æª”æ¡ˆ**: `configs/rtx4090_optimized.yaml`

## ğŸ¯ æº–å‚™å¥½äº†å—ï¼Ÿ

```bash
# ä¸€éµé–‹å§‹
cd /media/user/disk2/METAGENE/classification && bash test_optimized_training.sh
```

---

**ç‹€æ…‹**: âœ… Ready to Train  
**GPU**: RTX 4090 (24GB)  
**Peak Memory**: 13GB  
**Success Rate**: 100% âœ“

