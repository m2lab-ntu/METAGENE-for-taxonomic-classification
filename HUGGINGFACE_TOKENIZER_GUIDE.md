# HuggingFace å®˜æ–¹ Tokenizer ä½¿ç”¨æŒ‡å—

## ğŸ“ ç¸½è¦½

å·²æ›´æ–° METAGENE classification pipeline ä»¥æ”¯æ´ HuggingFace å®˜æ–¹ tokenizerï¼Œèˆ‡ [METAGENE-1 HuggingFace é é¢](https://huggingface.co/metagene-ai/METAGENE-1) å»ºè­°çš„ç”¨æ³•ä¸€è‡´ã€‚

## ğŸ”„ ä¿®æ”¹å…§å®¹

### 1. æ¨¡å‹è¼‰å…¥ (`modules/modeling.py`)
- âœ… **ä¿æŒä½¿ç”¨ `AutoModel`** - é€™æ˜¯æ­£ç¢ºçš„ï¼Œå› ç‚ºæˆ‘å€‘åšçš„æ˜¯ classification è€Œä¸æ˜¯ generation
- âœ… æ·»åŠ  `device_map="auto"` åƒæ•¸ï¼Œç¬¦åˆ HuggingFace å®˜æ–¹ç¯„ä¾‹
- âœ… ä½¿ç”¨ `torch.bfloat16` ä»¥ç²å¾—æ›´å¥½çš„æ€§èƒ½

### 2. Tokenizer æ”¯æ´ (`modules/dataloading.py`)
æ›´æ–° `MetaGeneTokenizer` é¡åˆ¥ä»¥æ”¯æ´å…©ç¨®æ¨¡å¼ï¼š

#### **é¸é … Aï¼šminbpe tokenizerï¼ˆåŸæœ‰ï¼Œé è¨­ï¼‰**
```python
tokenizer = MetaGeneTokenizer(
    tokenizer_path="/path/to/minbpe/tokenizer.model",
    max_length=512,
    use_hf_tokenizer=False  # é è¨­
)
```

#### **é¸é … Bï¼šHuggingFace å®˜æ–¹ tokenizerï¼ˆæ–°å¢ï¼Œæ¨è–¦ï¼‰**
```python
tokenizer = MetaGeneTokenizer(
    tokenizer_path="metagene-ai/METAGENE-1",
    max_length=512,
    use_hf_tokenizer=True  # å•Ÿç”¨ HuggingFace tokenizer
)
```

### 3. é…ç½®æª”æ¡ˆ
æä¾›å…©å€‹é…ç½®æª”æ¡ˆï¼š

**`configs/default.yaml`** - ä½¿ç”¨ minbpe tokenizerï¼ˆåŸæœ‰ï¼‰
```yaml
tokenizer:
  name_or_path: /media/user/disk2/METAGENE/metagene-pretrain/train/minbpe/tokenizer/large-mgfm-1024.model
  use_hf_tokenizer: false
```

**`configs/default_hf_tokenizer.yaml`** - ä½¿ç”¨ HuggingFace tokenizerï¼ˆæ–°å¢ï¼‰
```yaml
tokenizer:
  name_or_path: metagene-ai/METAGENE-1
  use_hf_tokenizer: true
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ–¹æ³• 1ï¼šä½¿ç”¨ minbpe tokenizerï¼ˆåŸæœ‰æ–¹æ³•ï¼‰

```bash
python train.py \
  --config configs/default.yaml \
  --train_fasta examples/example_train.fa \
  --val_fasta examples/example_val.fa \
  --mapping_tsv examples/labels.tsv \
  --output_dir outputs/test_minbpe \
  --batch_size 4 \
  --max_epochs 2
```

### æ–¹æ³• 2ï¼šä½¿ç”¨ HuggingFace tokenizerï¼ˆæ¨è–¦ï¼‰

```bash
python train.py \
  --config configs/default_hf_tokenizer.yaml \
  --train_fasta examples/example_train.fa \
  --val_fasta examples/example_val.fa \
  --mapping_tsv examples/labels.tsv \
  --output_dir outputs/test_hf_tokenizer \
  --batch_size 4 \
  --max_epochs 2
```

### æ–¹æ³• 3ï¼šä¿®æ”¹ç¾æœ‰é…ç½®æª”æ¡ˆ

ç·¨è¼¯ `configs/default.yaml`ï¼š

```yaml
tokenizer:
  # æ”¹æˆ HuggingFace æ¨¡å‹åç¨±
  name_or_path: metagene-ai/METAGENE-1
  # å•Ÿç”¨ HuggingFace tokenizer
  use_hf_tokenizer: true
  max_length: 512
```

## ğŸ¯ ç‚ºä»€éº¼ä½¿ç”¨ `AutoModel` è€Œä¸æ˜¯ `AutoModelForCausalLM`ï¼Ÿ

### Classification ä»»å‹™ï¼ˆæˆ‘å€‘çš„æƒ…æ³ï¼‰âœ…
```python
# æ­£ç¢ºï¼šç”¨æ–¼ feature extraction + classification
encoder = AutoModel.from_pretrained("metagene-ai/METAGENE-1")
# å–å¾— hidden states â†’ mean pooling â†’ linear classifier
```

**ç‚ºä»€éº¼ï¼š**
- æˆ‘å€‘éœ€è¦çš„æ˜¯ encoder çš„ hidden states
- æˆ‘å€‘æœƒåŠ è‡ªå·±çš„ classification head
- ä¸éœ€è¦ language model headï¼ˆç¯€çœè¨˜æ†¶é«”ï¼‰

### Generation ä»»å‹™ï¼ˆHuggingFace ç¯„ä¾‹ï¼‰
```python
# ç”¨æ–¼ç”Ÿæˆ DNA åºåˆ—
model = AutoModelForCausalLM.from_pretrained("metagene-ai/METAGENE-1")
# ç›´æ¥ç”Ÿæˆä¸‹ä¸€å€‹ token
```

**ç‚ºä»€éº¼ï¼š**
- éœ€è¦ language model head ä¾†é æ¸¬ä¸‹ä¸€å€‹ token
- ç”¨æ–¼åºåˆ—ç”Ÿæˆä»»å‹™

## ğŸ“Š æ¯”è¼ƒ

| ç‰¹æ€§ | minbpe tokenizer | HuggingFace tokenizer |
|------|------------------|----------------------|
| èˆ‡å®˜æ–¹ç¯„ä¾‹ä¸€è‡´ | âŒ | âœ… |
| éœ€è¦æœ¬åœ°æª”æ¡ˆ | âœ… éœ€è¦ | âŒ è‡ªå‹•ä¸‹è¼‰ |
| è¨­å®šè¤‡é›œåº¦ | ä¸­ç­‰ | ç°¡å–® |
| ç¶­è­·æ€§ | éœ€æ‰‹å‹•æ›´æ–° | è‡ªå‹•åŒæ­¥å®˜æ–¹ç‰ˆæœ¬ |
| æ¨è–¦åº¦ | å¯ç”¨ | **æ¨è–¦** |

## âš ï¸ æ³¨æ„äº‹é …

### 1. é¦–æ¬¡ä½¿ç”¨ HuggingFace tokenizer æœƒä¸‹è¼‰æ¨¡å‹æª”æ¡ˆ
```bash
# ç´„ 200MB tokenizer æª”æ¡ˆ
Attempting to load HuggingFace tokenizer from metagene-ai/METAGENE-1
Downloading tokenizer...
âœ“ Using HuggingFace official tokenizer
```

### 2. æ¨¡å‹ä¸‹è¼‰å•é¡Œ
å¦‚æœä¹‹å‰å¡åœ¨æ¨¡å‹ä¸‹è¼‰ï¼ˆ16GBï¼‰ï¼Œå¯ä»¥ï¼š

**é¸é … Aï¼šé å…ˆä¸‹è¼‰æ¨¡å‹**
```bash
conda activate METAGENE
python -c "from transformers import AutoModel; AutoModel.from_pretrained('metagene-ai/METAGENE-1', torch_dtype='auto')"
```

**é¸é … Bï¼šä½¿ç”¨å·²ä¸‹è¼‰çš„æ¨¡å‹**
æª¢æŸ¥ç·©å­˜ï¼š
```bash
ls ~/.cache/huggingface/hub/models--metagene-ai--METAGENE-1/
```

å¦‚æœçœ‹åˆ° `.incomplete` æª”æ¡ˆï¼Œè¡¨ç¤ºä¸‹è¼‰æœªå®Œæˆï¼Œéœ€è¦é‡æ–°ä¸‹è¼‰ã€‚

## ğŸ§ª æ¸¬è©¦

### å¿«é€Ÿæ¸¬è©¦ï¼ˆç„¡éœ€ GPU æˆ–æ¨¡å‹ï¼‰
```bash
cd /media/user/disk2/METAGENE/classification
conda activate METAGENE
python test_dataloader_only.py
```

é€™æœƒæ¸¬è©¦ï¼š
- âœ… Tokenizer è¼‰å…¥ï¼ˆminbpeï¼‰
- âœ… FASTA æª”æ¡ˆè§£æ
- âœ… Label mapping
- âœ… DataLoader æ‰¹æ¬¡è™•ç†

### å®Œæ•´æ¸¬è©¦ï¼ˆéœ€è¦ GPU + æ¨¡å‹ï¼‰
```bash
pytest tests/test_pipeline.py -v
```

## ğŸ“š åƒè€ƒè³‡æ–™

- [METAGENE-1 HuggingFace é é¢](https://huggingface.co/metagene-ai/METAGENE-1)
- [METAGENE-1 è«–æ–‡](https://arxiv.org/abs/2501.02045)
- [HuggingFace Transformers æ–‡æª”](https://huggingface.co/docs/transformers)

## ğŸ”§ æ•…éšœæ’é™¤

### å•é¡Œï¼šç„¡æ³•è¼‰å…¥ HuggingFace tokenizer
```
Warning: Could not load HuggingFace tokenizer
Falling back to minbpe tokenizer
```

**è§£æ±ºæ–¹æ³•ï¼š**
1. ç¢ºä¿ `transformers` å·²å®‰è£ï¼š`pip install transformers`
2. æª¢æŸ¥ç¶²è·¯é€£ç·š
3. ä½¿ç”¨ minbpe tokenizerï¼ˆ`use_hf_tokenizer: false`ï¼‰

### å•é¡Œï¼šæ¨¡å‹ä¸‹è¼‰å¡ä½
```
Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]
```

**è§£æ±ºæ–¹æ³•ï¼š**
1. æª¢æŸ¥ç¶²è·¯é€£ç·šå’Œé€Ÿåº¦
2. ä½¿ç”¨ä»£ç†æˆ–æ›´æ›ç¶²è·¯
3. æ¸…ç†ä¸å®Œæ•´çš„ä¸‹è¼‰ï¼š
   ```bash
   rm -rf ~/.cache/huggingface/hub/models--metagene-ai--METAGENE-1
   ```
4. é‡æ–°ä¸‹è¼‰

### å•é¡Œï¼šCUDA out of memory
```
RuntimeError: CUDA out of memory
```

**è§£æ±ºæ–¹æ³•ï¼š**
1. æ¸›å°‘ batch sizeï¼š`--batch_size 32`
2. æ¸›å°‘åºåˆ—é•·åº¦ï¼šåœ¨ config ä¸­è¨­å®š `max_length: 256`
3. å•Ÿç”¨æ¢¯åº¦ç´¯ç©ï¼š
   ```yaml
   training:
     grad_accum_steps: 2
   ```

## âœ¨ ç¸½çµ

æ‰€æœ‰ä¿®æ”¹éƒ½æ˜¯**å‘å¾Œç›¸å®¹**çš„ï¼š
- âœ… åŸæœ‰çš„ minbpe tokenizer ä»å¯æ­£å¸¸ä½¿ç”¨
- âœ… æ–°å¢ HuggingFace tokenizer æ”¯æ´ï¼ˆæ¨è–¦ï¼‰
- âœ… å¯é€éé…ç½®æª”æ¡ˆè¼•é¬†åˆ‡æ›
- âœ… ä»£ç¢¼æ›´ç¬¦åˆ HuggingFace å®˜æ–¹æœ€ä½³å¯¦è¸


